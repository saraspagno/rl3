{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21qwRKOJjPRH"
      },
      "source": [
        "# ğŸ® Deep RL Final Project â€” MiniGrid Environments\n",
        "\n",
        "## Overview\n",
        "In this project, you will train deep RL agents on two MiniGrid environments. You must implement the core algorithms yourself using concepts from class.\n",
        "\n",
        "**Read first:** Follow the instructions in the accompanying PDF. This notebook defines the environment APIs and where you may edit.\n",
        "\n",
        "## Learning objectives\n",
        "- Implement deep RL from scratch.\n",
        "- Design observation preprocessing and reward shaping.\n",
        "- Evaluate performance with clear metrics and plots.\n",
        "- Communicate results in a concise report.\n",
        "\n",
        "## ğŸŒ The Two Environments\n",
        "| Environment | Description | Actions | Goal |\n",
        "|-------------|-------------|---------|------|\n",
        "| **`SimpleGridEnv`** | 8Ã—8 empty room | 3 (Left, Right, Forward) | Navigate to the green goal square |\n",
        "| **`KeyDoorBallEnv`** | Two rooms with locked door | 5 (Left, Right, Forward, Pickup, Toggle) | Get key â†’ Open door â†’ Pick up ball â†’ Reach goal |\n",
        "\n",
        "## âœ… What You CAN Modify\n",
        "- **Preprocessing** â€” Implement your own observation preprocessing function.\n",
        "- **Reward shaping** â€” Modify rewards in each `step()` method (see `# TODO`).\n",
        "- **Observation space** â€” Update `self.observation_space` to match preprocessing output.\n",
        "\n",
        "## âŒ What You CANNOT Modify\n",
        "- Grid layout and generation logic.\n",
        "- Action spaces or termination conditions.\n",
        "- Environment mechanics (door/key/ball rules).\n",
        "- **No external RL libraries** for the core algorithm (you may use PyTorch/TensorFlow).\n",
        "\n",
        "## ğŸ“¦ Deliverables & Submission\n",
        "**Submit:** (1) this notebook with your full code and outputs, and (2) a report formatted **as specified in the instructions PDF**.\n",
        "\n",
        "## ğŸ§ª Reproducibility checklist\n",
        "- Set random seeds for Python, NumPy, and your DL framework.\n",
        "- Document hyperparameters.\n",
        "\n",
        "## ğŸ§¾ Academic integrity\n",
        "- You may discuss ideas, but code and write-up must be your own.\n",
        "- Cite any external resources (blog posts, papers, code snippets).\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXbtXcLijPRI"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZJef49pjPRI"
      },
      "source": [
        "## Installs and Imports"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4T3qcykHFi15"
      },
      "source": [
        "### Installs (run once if needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2dah0RrY9Kmj"
      },
      "outputs": [],
      "source": [
        "# TODO: Restore for Colab\n",
        "# %%capture\n",
        "# !sudo apt-get update\n",
        "# !sudo apt-get install -y xvfb ffmpeg freeglut3-dev\n",
        "# !pip install imageio\n",
        "# !pip install pyvirtualdisplay\n",
        "# !pip install gymnasium\n",
        "# !pip install minigrid\n",
        "# !pip install pygame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHbKbI7BwIwv"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "T9RBKvR_jPRJ"
      },
      "outputs": [],
      "source": [
        "# 1. Future Imports (Must be first)\n",
        "from __future__ import annotations\n",
        "\n",
        "# 2. Standard Library Imports\n",
        "import base64\n",
        "import copy\n",
        "import random\n",
        "import platform\n",
        "import os\n",
        "\n",
        "# 3. Third-Party Data & Visualization Imports\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import IPython\n",
        "from IPython.display import HTML\n",
        "\n",
        "# TODO: Restore this import when moving to Colab\n",
        "# import pyvirtualdisplay\n",
        "\n",
        "# 4. Gymnasium Imports\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "# 5. Minigrid Imports\n",
        "from minigrid.core.constants import COLOR_NAMES\n",
        "from minigrid.core.grid import Grid\n",
        "from minigrid.core.mission import MissionSpace\n",
        "from minigrid.core.world_object import Door, Goal, Key, Lava, Wall, Ball\n",
        "from minigrid.minigrid_env import MiniGridEnv as BaseMiniGridEnv\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# Configure Matplotlib for Notebook Environment\n",
        "%matplotlib inline\n",
        "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
        "plt.rcParams['image.interpolation'] = 'nearest'\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "# --- Platform-specific setup ---\n",
        "IS_COLAB = platform.system() == \"Linux\" and os.path.exists(\"/content\")\n",
        "\n",
        "# Create outputs directory for local development\n",
        "if not IS_COLAB:\n",
        "    os.makedirs(\"outputs\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7bJeRHbwMIj"
      },
      "source": [
        "### Display utils\n",
        "The cell below contains the video display configuration. No need to make changes here."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "z41WGwQt9i7_"
      },
      "outputs": [],
      "source": [
        "def embed_mp4(filename):\n",
        "    \"\"\"Embeds an mp4 file in the notebook.\"\"\"\n",
        "    video = open(filename,'rb').read()\n",
        "    b64 = base64.b64encode(video)\n",
        "    tag = '''\n",
        "    <video width=\"640\" height=\"480\" controls>\n",
        "      <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\">\n",
        "    Your browser does not support the video tag.\n",
        "    </video>'''.format(b64.decode())\n",
        "    return IPython.display.HTML(tag)\n",
        "\n",
        "def embed_gif(filename):\n",
        "    \"\"\"Embeds a GIF file in the notebook (for macOS/local without ffmpeg).\"\"\"\n",
        "    with open(filename, 'rb') as f:\n",
        "        gif_data = f.read()\n",
        "    b64 = base64.b64encode(gif_data).decode()\n",
        "    return IPython.display.HTML(f'<img src=\"data:image/gif;base64,{b64}\" width=\"640\">')\n",
        "\n",
        "def embed_video(filename):\n",
        "    \"\"\"Embeds video or GIF based on file extension.\"\"\"\n",
        "    if filename.endswith('.gif'):\n",
        "        return embed_gif(filename)\n",
        "    else:\n",
        "        return embed_mp4(filename)\n",
        "\n",
        "# TODO: Restore this block when moving to Colab\n",
        "# ----- COLAB ONLY: Virtual display setup -----\n",
        "# import pyvirtualdisplay\n",
        "# display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()\n",
        "# ----- END COLAB ONLY -----\n",
        "\n",
        "# macOS/local: No virtual display needed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aofVkAcHzG9h"
      },
      "source": [
        "# Environments\n",
        "\n",
        "> âš ï¸ **Important**\n",
        ">\n",
        "> The two environments below are **fixed**â€”do not modify grid layout, action spaces, or termination conditions.\n",
        ">\n",
        "> **You may modify only:**\n",
        "> 1. **Observation space** â€” set `self.observation_space` to match your preprocessing output (see `# TODO`).\n",
        "> 2. **Reward shaping** â€” edit reward logic inside `step()` (see `# TODO`).\n",
        ">\n",
        "> Look for the clearly marked sections in each environment class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "c3u5jj6DjPRJ"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ENVIRONMENT 1: SIMPLE GRID (Empty Room)\n",
        "# =============================================================================\n",
        "class SimpleGridEnv(BaseMiniGridEnv):\n",
        "    \"\"\"\n",
        "    A simple grid environment with no obstacles inside, just outer walls.\n",
        "    The agent and goal positions are randomized at each reset.\n",
        "\n",
        "    Actions:\n",
        "        0: Turn Left\n",
        "        1: Turn Right\n",
        "        2: Move Forward\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        size=10,\n",
        "        max_steps=1000,\n",
        "        render_mode=\"rgb_array\",\n",
        "        preprocess=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "\n",
        "        # Define a static mission string (not used by the agent typically)\n",
        "        mission_space = MissionSpace(mission_func=self._gen_mission)\n",
        "\n",
        "\n",
        "        super().__init__(\n",
        "            mission_space=mission_space,\n",
        "            grid_size=size,\n",
        "            see_through_walls=True,\n",
        "            max_steps=max_steps,\n",
        "            render_mode=render_mode,\n",
        "            highlight=False,\n",
        "            **kwargs,\n",
        "        )\n",
        "        # Discrete actions: 0: Turn Left, 1: Turn Right, 2: Move Forward\n",
        "        self.action_space = spaces.Discrete(3)\n",
        "\n",
        "        # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "        # â•‘  âœ… STUDENT TODO: Update observation_space to match preprocessing   â•‘\n",
        "        # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "        # Updated to match pre_process output: (84, 84, 1), float32, [0, 1]\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            shape=(84, 84, 1),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "        # â•‘                     END OF EDITABLE SECTION                         â•‘\n",
        "        # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "        # Preprocessing function for observations\n",
        "        self.preprocess = preprocess if preprocess is not None else lambda x: x\n",
        "        self.walls_init = []\n",
        "        # Default goal and agent starting position (overwritten in _gen_grid)\n",
        "        self.goal_pos = (self.width - 2, self.height - 2)\n",
        "        self.agent_start_pos = (1, 1)\n",
        "        self.agent_start_dir = 0\n",
        "\n",
        "\n",
        "    # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "    # â•‘  â›” DO NOT MODIFY: Core environment methods below                       â•‘\n",
        "    # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "    @staticmethod\n",
        "    def _gen_mission():\n",
        "        return \"grand mission\"\n",
        "\n",
        "    def _get_obs(self, obs=None):\n",
        "        \"\"\"Returns the current observation after applying preprocessing.\"\"\"\n",
        "        obs = self.get_frame(highlight=False, tile_size=32)\n",
        "        return self.preprocess(obs)\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        # 1. Randomize agent starting parameters before generating the grid\n",
        "        self.agent_start_pos = (random.randint(1, 6), random.randint(1, 6))\n",
        "        self.agent_start_dir = random.choice([0, 1, 2, 3])\n",
        "        # 2. Call parent reset, which internally calls _gen_grid()\n",
        "        obs, info = super().reset(seed=seed, options=options)\n",
        "        # 3. Return the preprocessed observation\n",
        "        return self._get_obs(obs), info\n",
        "\n",
        "    def _gen_grid(self, width, height):\n",
        "        \"\"\"Procedurally generates the grid layout: walls, goal, and agent.\"\"\"\n",
        "        self.grid = Grid(width, height)\n",
        "\n",
        "        # 1. Create the outer boundary walls\n",
        "        self.grid.wall_rect(0, 0, width, height)\n",
        "\n",
        "        # 2. Place internal walls (if any defined in self.walls_init)\n",
        "        for column, row in self.walls_init:\n",
        "            self.grid.set(column, row, Wall())\n",
        "\n",
        "        # 3. Randomize Goal Position (Top-Right, Bottom-Right, Bottom-Left corners roughly)\n",
        "        self.goal_pos = random.choice([(8,1), (8,8), (1,8)])\n",
        "        self.put_obj(Goal(), self.goal_pos[0], self.goal_pos[1])\n",
        "\n",
        "        # 4. Place Agent\n",
        "        self.agent_pos = self.agent_start_pos\n",
        "        self.agent_dir = self.agent_start_dir\n",
        "\n",
        "        self.mission = \"grand mission\"\n",
        "\n",
        "    # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "    # â•‘  âœ… STUDENT TODO: Modify reward shaping below                           â•‘\n",
        "    # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Standard step function.\n",
        "\n",
        "        Current reward scheme (sparse):\n",
        "            - +1.0 when reaching the goal (terminated=True)\n",
        "            - 0.0 otherwise\n",
        "\n",
        "        ğŸ’¡ You can add reward shaping here\n",
        "        \"\"\"\n",
        "        obs, reward, terminated, truncated, info = super().step(action)\n",
        "\n",
        "        # ----- REWARD SHAPING: EDIT BELOW THIS LINE -----\n",
        "        if terminated:\n",
        "            reward = 1.0\n",
        "        else:\n",
        "            reward = 0.0\n",
        "        # ----- REWARD SHAPING: EDIT ABOVE THIS LINE -----\n",
        "\n",
        "        return self._get_obs(obs), reward, terminated, truncated, info\n",
        "    # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "    # â•‘                     END OF EDITABLE SECTION                             â•‘\n",
        "    # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "e_IdnkEzjPRJ"
      },
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ENVIRONMENT 2: KEY-DOOR WITH BALL PICKUP\n",
        "# =============================================================================\n",
        "class KeyDoorBallEnv(BaseMiniGridEnv):\n",
        "    \"\"\"\n",
        "    Grid environment with two rooms separated by a locked door.\n",
        "\n",
        "    Task sequence:\n",
        "        1. Pick up key -> 2. Unlock door -> 3. Pick up ball -> 4. Reach goal\n",
        "\n",
        "    Actions:\n",
        "        0: Turn Left\n",
        "        1: Turn Right\n",
        "        2: Move Forward\n",
        "        3: Pick Up\n",
        "        4: Toggle (open/close door)\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "        self,\n",
        "        size=10,\n",
        "        max_steps=1000,\n",
        "        render_mode=\"rgb_array\",\n",
        "        partition_col=3,\n",
        "        require_ball_pickup=True,\n",
        "        preprocess=None,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        self.agent_start_pos = (1, 1)\n",
        "        self.agent_start_dir = 0\n",
        "        self.partition_col = partition_col\n",
        "        self.walls_init = []\n",
        "        self.inventory = []\n",
        "        self.require_ball_pickup = require_ball_pickup\n",
        "        self.preprocess = preprocess if preprocess is not None else lambda x: x\n",
        "\n",
        "        mission_space = MissionSpace(mission_func=self._gen_mission)\n",
        "        super().__init__(\n",
        "            mission_space=mission_space,\n",
        "            grid_size=size,\n",
        "            see_through_walls=True,\n",
        "            max_steps=max_steps,\n",
        "            render_mode=render_mode,\n",
        "            highlight=False,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        # 5 actions: left, right, forward, pickup, toggle\n",
        "        self.action_space = spaces.Discrete(5)\n",
        "\n",
        "        # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "        # â•‘  âœ… STUDENT TODO: Update observation_space to match preprocessing   â•‘\n",
        "        # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "        # Updated to match pre_process output: (84, 84, 1), float32, [0, 1]\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            shape=(84, 84, 1),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "        # â•‘                     END OF EDITABLE SECTION                         â•‘\n",
        "        # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "        # State tracking for reward shaping (you can use these in your reward logic)\n",
        "        self.prev_key = False\n",
        "        self.prev_door = False\n",
        "        self.prev_ball = False\n",
        "\n",
        "    # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "    # â•‘  â›” DO NOT MODIFY: Core environment methods below                       â•‘\n",
        "    # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "    @staticmethod\n",
        "    def _gen_mission():\n",
        "        return \"Pick up the key to open the door, pick up the ball, then reach the goal\"\n",
        "\n",
        "    def _get_obs(self, obs=None):\n",
        "        \"\"\"Returns the current observation after applying preprocessing.\"\"\"\n",
        "        obs = self.get_frame(highlight=False, tile_size=32)\n",
        "        return self.preprocess(obs)\n",
        "\n",
        "    def reset(self, *, seed=None, options=None):\n",
        "        # Reset state tracking\n",
        "        self.prev_key = False\n",
        "        self.prev_door = False\n",
        "        self.prev_ball = False\n",
        "        self.inventory = []\n",
        "\n",
        "        # Call parent reset, which internally calls _gen_grid()\n",
        "        obs, info = super().reset(seed=seed, options=options)\n",
        "\n",
        "        return self._get_obs(obs), info\n",
        "\n",
        "    def _gen_grid(self, width, height):\n",
        "        \"\"\"Generate grid: walls, partition, door, key, ball, goal, agent.\"\"\"\n",
        "        # Grid with outer walls\n",
        "        self.grid = Grid(width, height)\n",
        "        self.grid.wall_rect(0, 0, width, height)\n",
        "\n",
        "        # Partition wall\n",
        "        self.walls_init = [(self.partition_col, i) for i in range(height)]\n",
        "        for col, row in self.walls_init:\n",
        "            if 0 <= col < width and 0 <= row < height:\n",
        "                self.grid.set(col, row, Wall())\n",
        "\n",
        "        # Key in left room\n",
        "        self.key_pos = (\n",
        "            random.choice(range(1, self.partition_col)),\n",
        "            random.choice(range(2, height - 1))\n",
        "        )\n",
        "        self.grid.set(self.key_pos[0], self.key_pos[1], Key(COLOR_NAMES[0]))\n",
        "\n",
        "        # Door in partition\n",
        "        door_y = random.choice(range(1, height - 1))\n",
        "        self.door_pos = (self.partition_col, door_y)\n",
        "        self.env_door = Door(COLOR_NAMES[0], is_locked=True)\n",
        "        self.grid.set(self.door_pos[0], self.door_pos[1], self.env_door)\n",
        "\n",
        "        # Goal\n",
        "        self.goal_pos = (8, 8)\n",
        "        self.put_obj(Goal(), self.goal_pos[0], self.goal_pos[1])\n",
        "\n",
        "        # Ball in right room (if required)\n",
        "        if self.require_ball_pickup:\n",
        "            right_x = range(self.partition_col + 2, width - 2)\n",
        "            right_y = range(1, height - 1)\n",
        "            while True:\n",
        "                ball_x = random.choice(list(right_x))\n",
        "                ball_y = random.choice(list(right_y))\n",
        "                self.ball_pos = (ball_x, ball_y)\n",
        "                if self.ball_pos != self.goal_pos:\n",
        "                    break\n",
        "\n",
        "            self.grid.set(ball_x, ball_y, Ball(COLOR_NAMES[1]))\n",
        "\n",
        "        # Agent\n",
        "        self.agent_pos = self.agent_start_pos\n",
        "        self.agent_dir = self.agent_start_dir\n",
        "\n",
        "    def try_pickup_ball(self):\n",
        "        \"\"\"Pick up ball in front and add to inventory.\"\"\"\n",
        "        obj = self.grid.get(self.front_pos[0], self.front_pos[1])\n",
        "        if isinstance(obj, Ball):\n",
        "            self.grid.set(self.front_pos[0], self.front_pos[1], None)\n",
        "            self.inventory.append(obj)\n",
        "\n",
        "    # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "    # â•‘  âœ… STUDENT TODO: Modify reward shaping below                           â•‘\n",
        "    # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "    def step(self, action):\n",
        "        \"\"\"\n",
        "        Step function with sparse reward.\n",
        "\n",
        "        Available helper methods for reward shaping:\n",
        "            - self.is_carrying_key()  : Returns True if agent has the key\n",
        "            - self.is_carrying_ball() : Returns True if agent has the ball\n",
        "            - self.is_door_open()     : Returns True if door is open\n",
        "            - self.prev_key           : Key status before this step\n",
        "            - self.prev_door          : Door status before this step\n",
        "            - self.prev_ball          : Ball status before this step\n",
        "\n",
        "        Current reward scheme (sparse):\n",
        "            - +1.0 for reaching goal with ball\n",
        "            - 0.0 otherwise\n",
        "\n",
        "        ğŸ’¡ You can add reward shaping here\n",
        "        \"\"\"\n",
        "        # Map action 4 to toggle (internal MiniGrid uses 5 for toggle)\n",
        "        if action == 4:\n",
        "            action = 5\n",
        "\n",
        "        # Track previous state for reward shaping\n",
        "        self.prev_key = self.is_carrying_key()\n",
        "        self.prev_door = self.is_door_open()\n",
        "        self.prev_ball = self.is_carrying_ball()\n",
        "\n",
        "        # Handle ball pickup\n",
        "        if action == 3:\n",
        "            self.try_pickup_ball()\n",
        "\n",
        "        # Standard step\n",
        "        obs, reward, terminated, truncated, info = super().step(action)\n",
        "\n",
        "        # Goal only counts if ball is picked up (when required)\n",
        "        terminated = terminated and (not self.require_ball_pickup or self.is_carrying_ball())\n",
        "\n",
        "        # ----- REWARD SHAPING: EDIT BELOW THIS LINE -----\n",
        "        if terminated:\n",
        "            reward = 1.0\n",
        "        else:\n",
        "            reward = 0.0\n",
        "        # ----- REWARD SHAPING: EDIT ABOVE THIS LINE -----\n",
        "\n",
        "        return self._get_obs(obs), reward, terminated, truncated, info\n",
        "    # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "    # â•‘                     END OF EDITABLE SECTION                             â•‘\n",
        "    # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "    # â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "    # â•‘  â›” DO NOT MODIFY: State getter methods (use these in reward shaping)   â•‘\n",
        "    # â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "    def is_carrying_key(self):\n",
        "        \"\"\"Check if agent has key (in hand or inventory).\"\"\"\n",
        "        key_in_hand = self.carrying and isinstance(self.carrying, Key)\n",
        "        key_in_inventory = any(isinstance(item, Key) for item in self.inventory)\n",
        "        return key_in_hand or key_in_inventory\n",
        "\n",
        "    def is_carrying_ball(self):\n",
        "        \"\"\"Check if agent has ball (in hand or inventory).\"\"\"\n",
        "        ball_in_hand = self.carrying and isinstance(self.carrying, Ball)\n",
        "        ball_in_inventory = any(isinstance(item, Ball) for item in self.inventory)\n",
        "        return ball_in_hand or ball_in_inventory\n",
        "\n",
        "    def is_door_open(self):\n",
        "        \"\"\"Returns True if the door is open.\"\"\"\n",
        "        if hasattr(self, 'env_door'):\n",
        "            return self.env_door.is_open\n",
        "        return False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MHBOpXqjPRJ"
      },
      "source": [
        "# Preprocessing Method\n",
        "\n",
        "> ğŸ’¡ **Student task:** Implement your own preprocessing function below.\n",
        ">\n",
        "> Your preprocessing function should:\n",
        "> 1. Take a raw RGB image (320Ã—320Ã—3) as input.\n",
        "> 2. Return a processed observation that **exactly matches** your `observation_space` (shape, dtype, value range).\n",
        ">\n",
        "> Common preprocessing techniques:\n",
        "> - Crop edges to remove borders\n",
        "> - Convert to grayscale\n",
        "> - Resize to smaller dimensions\n",
        "> - Normalize pixel values\n",
        ">\n",
        "> **Reminder:** Update `self.observation_space` in both environment classes to match your output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WvzHckRdjPRJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "objc[94613]: Class SDLApplication is implemented in both /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x1169292c8) and /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x149754890). One of the two will be used. Which one is undefined.\n",
            "objc[94613]: Class SDLAppDelegate is implemented in both /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x116929318) and /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x1497548e0). One of the two will be used. Which one is undefined.\n",
            "objc[94613]: Class SDLTranslatorResponder is implemented in both /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x116929390) and /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x149754958). One of the two will be used. Which one is undefined.\n",
            "objc[94613]: Class SDLMessageBoxPresenter is implemented in both /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x1169293b8) and /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x149754980). One of the two will be used. Which one is undefined.\n",
            "objc[94613]: Class SDL_cocoametalview is implemented in both /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x116929408) and /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x1497549d0). One of the two will be used. Which one is undefined.\n",
            "objc[94613]: Class SDLOpenGLContext is implemented in both /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x116929458) and /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x149754a20). One of the two will be used. Which one is undefined.\n",
            "objc[94613]: Class SDL_ShapeData is implemented in both /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x1169294d0) and /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x149754a98). One of the two will be used. Which one is undefined.\n",
            "objc[94613]: Class SDL_CocoaClosure is implemented in both /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x116929520) and /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x149754ae8). One of the two will be used. Which one is undefined.\n",
            "objc[94613]: Class SDL_VideoData is implemented in both /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x116929570) and /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x149754b38). One of the two will be used. Which one is undefined.\n",
            "objc[94613]: Class SDL_WindowData is implemented in both /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x1169295c0) and /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x149754b88). One of the two will be used. Which one is undefined.\n",
            "objc[94613]: Class SDLWindow is implemented in both /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x1169295e8) and /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x149754bb0). One of the two will be used. Which one is undefined.\n",
            "objc[94613]: Class Cocoa_WindowListener is implemented in both /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x116929610) and /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x149754bd8). One of the two will be used. Which one is undefined.\n",
            "objc[94613]: Class SDLView is implemented in both /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x116929688) and /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x149754c50). One of the two will be used. Which one is undefined.\n",
            "objc[94613]: Class METAL_RenderData is implemented in both /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x116929700) and /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x149754cc8). One of the two will be used. Which one is undefined.\n",
            "objc[94613]: Class METAL_TextureData is implemented in both /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x116929750) and /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x149754d18). One of the two will be used. Which one is undefined.\n",
            "objc[94613]: Class SDL_RumbleMotor is implemented in both /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x116929778) and /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x149754d40). One of the two will be used. Which one is undefined.\n",
            "objc[94613]: Class SDL_RumbleContext is implemented in both /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/pygame/.dylibs/libSDL2-2.0.0.dylib (0x1169297c8) and /Users/saraspagnoletto/codingProjects/rl3/.venv/lib/python3.12/site-packages/cv2/.dylibs/libSDL2-2.0.0.dylib (0x149754d90). One of the two will be used. Which one is undefined.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "\n",
        "# =============================================================================\n",
        "# PREPROCESSING CONFIGURATION\n",
        "# =============================================================================\n",
        "# Standard size for Deep RL (same as Atari DQN benchmarks)\n",
        "PREPROCESS_SIZE = (84, 84)\n",
        "\n",
        "# Whether to normalize pixel values to [0, 1] range\n",
        "# Set to True for neural network training (recommended)\n",
        "# Set to False to keep uint8 [0, 255] range\n",
        "NORMALIZE_PIXELS = True\n",
        "\n",
        "\n",
        "def pre_process(img):\n",
        "    \"\"\"\n",
        "    Preprocess raw RGB observation from the environment for Deep RL.\n",
        "    \n",
        "    Pipeline:\n",
        "    1. Convert RGB to grayscale (reduces 3 channels to 1)\n",
        "    2. Resize from 320x320 to 84x84 (reduces computation by ~14x)\n",
        "    3. Normalize pixel values to [0, 1] range (helps neural network training)\n",
        "    \n",
        "    Input:  RGB image (320, 320, 3), dtype=uint8, values in [0, 255]\n",
        "    Output: Grayscale image (84, 84, 1), dtype=float32, values in [0, 1]\n",
        "    \n",
        "    Why these choices:\n",
        "    - Grayscale: Color is not essential for navigation; reduces input size\n",
        "    - 84x84: Standard size for DRL (DQN paper), balances detail vs computation\n",
        "    - Normalization: Neural networks train better with inputs in [0, 1] range\n",
        "    \"\"\"\n",
        "    # Step 1: Convert RGB to grayscale\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "    \n",
        "    # Step 2: Resize to smaller dimensions\n",
        "    resized = cv2.resize(gray, PREPROCESS_SIZE, interpolation=cv2.INTER_AREA)\n",
        "    \n",
        "    # Step 3: Normalize to [0, 1] range if enabled\n",
        "    if NORMALIZE_PIXELS:\n",
        "        normalized = resized.astype(np.float32) / 255.0\n",
        "    else:\n",
        "        normalized = resized.astype(np.uint8)\n",
        "    \n",
        "    # Step 4: Add channel dimension (84, 84) -> (84, 84, 1)\n",
        "    return np.expand_dims(normalized, axis=-1)\n",
        "\n",
        "\n",
        "# Helper function to get the observation space that matches preprocessing output\n",
        "def get_preprocessed_observation_space():\n",
        "    \"\"\"\n",
        "    Returns the observation space that matches the pre_process output.\n",
        "    Use this to update self.observation_space in environment classes.\n",
        "    \"\"\"\n",
        "    if NORMALIZE_PIXELS:\n",
        "        return spaces.Box(\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            shape=(PREPROCESS_SIZE[0], PREPROCESS_SIZE[1], 1),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "    else:\n",
        "        return spaces.Box(\n",
        "            low=0,\n",
        "            high=255,\n",
        "            shape=(PREPROCESS_SIZE[0], PREPROCESS_SIZE[1], 1),\n",
        "            dtype=np.uint8\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PREPROCESSING VERIFICATION\n",
        "# =============================================================================\n",
        "# Test the preprocessing function to make sure it works correctly\n",
        "\n",
        "# Create a test environment\n",
        "test_env = SimpleGridEnv(preprocess=pre_process)\n",
        "test_obs, _ = test_env.reset()\n",
        "\n",
        "# Get raw observation for comparison\n",
        "raw_obs = test_env.render()\n",
        "\n",
        "# Visualize the preprocessing\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "# Original raw observation\n",
        "axes[0].imshow(raw_obs)\n",
        "axes[0].set_title(f'Raw Observation\\nShape: {raw_obs.shape}, dtype: {raw_obs.dtype}')\n",
        "axes[0].axis('off')\n",
        "\n",
        "# Preprocessed observation (squeeze for display)\n",
        "preprocessed_display = test_obs.squeeze()  # Remove channel dimension for imshow\n",
        "axes[1].imshow(preprocessed_display, cmap='gray')\n",
        "axes[1].set_title(f'Preprocessed Observation\\nShape: {test_obs.shape}, dtype: {test_obs.dtype}')\n",
        "axes[1].axis('off')\n",
        "\n",
        "# Pixel value distribution\n",
        "axes[2].hist(test_obs.flatten(), bins=50, edgecolor='black')\n",
        "axes[2].set_title(f'Pixel Value Distribution\\nMin: {test_obs.min():.3f}, Max: {test_obs.max():.3f}')\n",
        "axes[2].set_xlabel('Pixel Value')\n",
        "axes[2].set_ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"PREPROCESSING SUMMARY\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Raw observation:         {raw_obs.shape}, dtype={raw_obs.dtype}\")\n",
        "print(f\"Preprocessed observation: {test_obs.shape}, dtype={test_obs.dtype}\")\n",
        "print(f\"Value range:             [{test_obs.min():.3f}, {test_obs.max():.3f}]\")\n",
        "print(f\"Observation space:       {test_env.observation_space}\")\n",
        "print(f\"{'='*60}\")\n",
        "\n",
        "# Cleanup\n",
        "test_env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDgIa_NOjPRJ"
      },
      "source": [
        "# ğŸ” Environment Examples & Exploration\n",
        "Run the cells below to understand each environment before implementing your solution.\n",
        "Use these quick tests to verify preprocessing output shape and rendering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWlbg9r96_08"
      },
      "source": [
        "## Environment 1: SimpleGridEnv (Empty Room)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E22QYJKSyEsF"
      },
      "source": [
        "**Task**: Navigate to the green goal square in an empty 8Ã—8 room.\n",
        "\n",
        "| Property | Value |\n",
        "|----------|-------|\n",
        "| Grid Size | 8Ã—8 |\n",
        "| Agent Start | Random position (1-6, 1-6) |\n",
        "| Agent Direction | Random (0-3) |\n",
        "| Goal Position | Random: (8,1), (1,8), or (8,8) |\n",
        "| Actions | 0: Turn Left, 1: Turn Right, 2: Move Forward |\n",
        "| Sparse Reward | +1.0 on reaching goal, 0.0 otherwise |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSe2m1kWwQ5L"
      },
      "source": [
        "### Quick Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "bGwG4ekDoPB-",
        "outputId": "f7e195af-bd9c-489a-b4e3-248a1f3d527b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== SimpleGridEnv ===\n",
            "Action space:       Discrete(3)\n",
            "Number of actions:  3\n",
            "Observation space:  Box(0, 255, (320, 320, 1), uint8)  (ensure it matches preprocessing output)\n",
            "Observation shape:  (320, 320, 1)\n",
            "Agent direction:    1\n",
            "Agent position:     (1, 4)\n",
            "Goal position:      (1, 8)\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABBEAAAHqCAYAAABSltYWAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjgsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvwVt1zgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJ6VJREFUeJzt3QV0bFf9NuBz4eIUd+gfipZCoTgtTqG4k+BQSoIVXUBxbXEorgnuCb6Kuxa3C8X1FneK2/nWez5O1mTuJPmlvUnuJM+zVkjv5MyZPXtC9j7v2bKtbdu2AQAAAFjByVY6AAAAAECIAAAAAJQZiQAAAACUCBEAAACAEiECAAAAUCJEAAAAAEqECAAAAECJEAEAAAAoESIAAAAAJUIENtQFLnCB5tBDD92Q137c4x7XbNu2rRmnenjlK1/ZlflHP/pRsyf773//21zykpdsnvjEJzZ7gitf+crNEUccsdHFAABWkP5Q+kVrIee98Y1vvCU/g43sc7P5CBFYEzt27GhufetbN+c///mbU5/61M15z3ve5rrXvW7zvOc9b1PV+Cc+8YlmcnKye3+nPOUpmzOe8YzNla50peYJT3hC88tf/nJdynDNa16zCxZGfe27777NRnjDG97Q7Ny5s7nPfe7T7Ake+tCHNi94wQuaX/ziFxtdFAA2QB/C91/pm1z0ohft2qn1aq/Z/dq2bV7zmtc0V7/61ZsznelMzWlPe9pm//337/phf/nLX7ZclX/605/ubpL94Q9/2OiisMlt3+gCsDn/gF3rWtdq/u///q+Znp5uznWuc3UXlJ/5zGea5zznOc1973vfhWO//e1vNyc72XhmWY95zGOaI488srngBS/YJbv5/ve//7354he/2Dzzmc9sXvWqVzXf//73S+c6qfVwvvOdr3nyk5+8y+MJNTbC05/+9Oa2t73thr3+sJvd7GbNGc5whuaFL3xh17EAYGtKG7DPPvt07fUnP/nJ5kUvelHz7ne/u/n617/eXYAyPv7zn/80t7/97Zu5ubnmale7WnfxnM8wN3ge//jHN/Pz880HP/jB5pznPGezlfrgee/plyZUGTTOfW72PEIEdrsMYc/F4+c///ld/oD96le/WvTvU53qVGP5CbzpTW/qAoSMQkgCnlEIg571rGd1Xyul5+nEnOY0pznJ9ZD6vuMd79jsCb785S83X/3qV7sgZSW5S3C6051uzcuURjMjY1796ld3jeueMo0FgPV1gxvcoLn85S/f/ffU1FRz1rOetTn66KObd7zjHc3tbne7DW2r1vu1xt3Tnva0LkB48IMf3N286N397nfv+mc3v/nNu4vp97znPc2eZiM+53Htc7NnEkex2+Xu+yUucYldAoQ4xznOsez8rH64Ye4O3O9+92vOfvazd+e5xz3u0fzzn//shmfd+c53bs585jN3X5nnnovxXtYKyPOf8YxndBfxmU6Ri/RrXOMa3V2Gite+9rXN5S53ue55ZznLWbo76hlJMTwK4WxnO1vzspe9bJcAob+oTyI+ah7e+973vq4Dk/O/5CUvGVkP8Y1vfKO59rWv3R2XkQZHHXVUt9bASV0D4nvf+95CQp1y3vWud23++te/LhyXtQwykmRYXjvTNnIxvpy3v/3tXZ1kaOGo1z/uuOO6Owf5/K561at2P/va1762MJojQ0wzeuWwww5rfvvb3y48P8fk+e985zsXHsuojzx22ctedpdOYqaVDMp0mh//+MfNV77ylXKdAbC5pZ2NH/7wh933tEWnP/3pu77MDW94w2avvfZq7nCHOyy0g89+9rO7Pk7aqtzhTv/k97///cj2/v3vf39zwAEHdMfut99+zVvf+tZFx/V9no997GPNve99766PlPa+l9Fzea1c/J3nPOdpDj/88JHD1D/72c92ZU27mgvTS13qUt3Iz0Hf+ta3uvY7/ZqUJ/2QwfY0/vWvf3VB+0UucpHumAQsaac/8IEPLByTaYHpN6ScKde5z33ubrTf8FpNuXDP6ICUJ3V4oxvdqOvXjOozpN+R18v3t73tbYVPrWn+9re/dcFBpqSMGol5k5vcpLnLXe7SvPe97+1Gwg5b6bOp1EW1Xpf6nN/85jcvPD4s/cP8rO+7VvpJ6Wc95CEP6f47o236qTv9ZzOqr/mDH/ygmZiY6MqfURxZQ+pd73rXomM++tGPdudJYJMbhSl7ynDwwQd3fUq2JiMR2O1y4X7sscd2f/jSIJwYmfKQP5D5A54//i996Uu7i94M08o0iSc96Und8MM0IHmNBAuDcsf5hBNO6Brc3O1PY5qOQtZqWG5YW/44PvrRj+4S7Nyh+PWvf92t45AL4txhTxm+853vdF/5eToaq5GhZLnTkU5Hpnpc7GIXG3lcGulcyP/73/9uHvawh3WNcOoggcJSQ/p+85vf7PJ4jh9OuvPe0rik0f3Sl77UzM7Odg3aU5/61O7nt7nNbbqGKGXIZ9BLsPOzn/2sC1WWk88on8kpTnGKkT9PY5VGOZ9hHwClUU5Dlo5JXjMdjbzffM/nn8Yr50z9f/zjH29uetObds/LkMWMMsjIhz/96U/dlIV08lKG3IkYlGAoPvWpTzWXucxlln0PAGwN/bTDXCT20vZe73rX6y4ac1Oin+aQtjsXhGmrcqMjwcPzn//8rn+QtmWw3fvud7/btaf3vOc9u4vZV7ziFV37l4vahNqDcmGZmya5QdHP4087nD7Qda5zneZe97pX13/I1IuM8hx8rbSfCSxyMX//+9+/a0O/+c1vNsccc0z370hbepWrXKW7EdD3KXJBmDv1b3nLW5pb3OIWC6+ZvkH6N1e84hW7dvULX/hC11foy3yrW92qO1/6abkozQjTlOEnP/nJwmKIGaGZ95w6TN8iNypS9tRn6qo/LhfyOV8u4vO6uSDuA4qVpE+S8Cbvcfv20Zcz6Rum3lMXuThezWdTqYtqvS71OSdYST8yz8nNruERrwmQ+n50pZ90y1vesuufZl2q3EjLza7Ia46StUAOOuig7vPJ73P+P5CpuOljJeAYLv9TnvKUrs+VkR9//OMfu5EgCdgSYrEFtbCbvf/9729PfvKTd18HHnhge8QRR7Tve9/72n/+85+7HHv+85+/vctd7rLw71e84hW5qmyvd73rtf/9738XHs95tm3b1t7znvdceOzf//53e77zna+9xjWusfDYD3/4w+75pznNadrjjz9+4fHPfvaz3eMPfOADFx577GMf2z3W+9GPftSV+YlPfOKiMu7YsaPdvn37wuPveMc7uuc9+9nPXnRcyvvrX/960de//vWvRe81z3vve9+7Yj084AEP6I5NuXu/+tWv2jOe8Yzd43mfvbz/PDbq6x73uMcu7/ewww5b9Nq3uMUt2rOe9awL//72t7/dHfe85z1v0XH3vve929Of/vTtX//613Y5+Uxudatb7fJ4//q3u93tdvnZqHO+4Q1v6I7/+Mc/vvDYjW50o/aKV7ziwr9vectbdl/53N7znvd0j33pS1/qnpfPadgpT3nK9l73utey5Qdg8+n7Fx/84Ae79nnnzp3tG9/4xq79G+wzpC3OcQ972MMWPf8Tn/hE9/jrXve6RY+nTR9+vG/v3/KWtyw89sc//rE997nP3V7mMpfZpUxXvepVuz7NYHuf9uqQQw5p//Of/yw8/vznP787/uUvf3n37zxnn3326V7v97///aJyDfahDj744Hb//fdv//73vy/6+UEHHdRe5CIXWXjs0pe+dNfOLiWvkdd/+tOfvuQxJ5xwQnumM52pnZ6eXvT4L37xi64PM/j4AQcc0NXJH/7wh0V9yLxG3tNy0gfLcW9729uWPOZ3v/tdd0z6Cav9bFaqi9XU61Kfc6RPdI5znGPR4z//+c/bk53sZO0TnvCEVfeT8tkM9xNX6mvmd3vw88vv1AUucIGF372PfOQj3XEXv/jF23/84x8Lxz7nOc/pHk8/ma3HdAZ2uyS0GYmQJDN3iJNUJo1OUjs8xGspd7vb3RbNW8/Q9Ny1zuO9k5/85N2wsSSzw5IC5/V6SZFzjoxeWEqGsuUudu7U565+/5XEN3fOP/KRj3THJY2O4VEISWWT9g5+DQ+dzwiA1MVKUs6k5il3L+frh1QOS6qflHr46wEPeMAuxyZ5H5Thhkn/+/eVoYEZ4pcUfHCkQ1LpDA9cajREL+fKkMqlDL9+DJ4zI0dS7/1dg6T+g2XNv/s7NbkTkSGcKW9GJUS+53ennyoxKOUaNWIDgK0hd/bTnu69997dyLq05RlCP9hniNz9H5RF+jIFMH2cwT5CRrnlHH0foZfpB4N3cjNSLnfGcyd+eKegjExMn6aXxQAzhTNt+OBCeDku5+mHm+dcGQ2R44ankPZ9qN/97nfNhz/84a5vkxGafbnTVqc/krvyP/3pT7tjc47c2c5jo6StznTFDG8fnsLRS98jUy4y6nKwnvL+0g/r6+nnP/9510fKSIDBRZhTvxmZsJK8l8hUiaX0P+v7N6v5bFaqi9XU61Kfc2REREZzpE576W+lP5qfrbaftBrpa6afOdhfyu9yRnJmCkSmnw7KKIjBKbzpk8Wofjibn+kMrIkrXOEK3UV5GsEECWmgM7Qq88bSaKzUQGTKwqC+gUmjP/z4qIYsF/3DcnGcIWNLyR/8BBWjnhv90MG+Ufrzn/+86Of5w9vPlcsQvcFFfgZDhIrM3R+e0x9LTX/IELp0jCqG67a/4E89piGNNFyPeMQjugYwHas0bmnkBhu05QyuU1GpgzTGGbb5xje+cZfFNxPODDZYGWaakCq/Czk2j6WhHwwR8vuV+X2jymVRRYCtK9v9pj+QIfCZ3ph2dXjF+vxseEh9+ghpj4bXduoNt10XvvCFd2lv8rqRC7TB6YLD7WL6AKPa/FzAZU58//N+KsZyU0czZz1tX6Zq5mupsqetz84VWd8g5cw5r3/96zd3utOdujUWImsgZHrCgx70oK7uchGbqRS5AO/fT3/R3a81MazvZ/TvYVSfK+97pQvjvi/WhwmrCRoqn81KdbGael2u/5Pzpi+bGzdZYyDy37k50pdpNf2k1Viqr3nxi1984eeDv1vL9R/ZeoQIrKk0eAkU8pU/hkkxk+Y/9rGPXfZ5w0ntco8vd8G6Gkl906hkMaBRr9OPPNh3332778MLNabT0V/IH3/88SNfY6W7+OthqbodrMeEBQ9/+MO7zyp3OBK+pJFLY7eSzKlbrkEZVQdJ8rOOQRYESsOZus7nkdcbXEwyI0+ymE/WRUhjls5cfq8SJGQBqn/84x9diDA8j6+XuyP9HEEAtp7cee13Z1hKLpaHg4W0RWlzXve61418zlLzzivWsm/Qt6GZx77USMhcVEfWf0owkZ0qcjMkayblBtCLX/zibm2ASJ8goxKzIGIWis4FdNYOyF35rDfUv17WRRgMSnpLrV+wWv2FbhYczOjTUfKzqIxsGLZSXaymXpf7nPO7lvLnZlv6MVmnIGteZN2oE9NP2uj+I1uHEIF10zfaGcK21kYNP8tiM/1iPqNc6EIX6v4QJikeTH9HJeRJztOAZpXmtdiiJ4tTjnoPWVhpPaQO0tFKGn6f+9ynG1WSRq6yPVBCln6V64oEDh/60Ie6hD2LDfVGvf+EUilXgoKECP1QunxPgJDOXRrg4Z0hIqMqMjKm73gAQFX6CJlmkIX0Khf9/Z3qwTve6YfEcn2Rvg/Qt/kZedBLG5b2tb9hkTL1NzWWGo3YPz+jKSsjFjOKLzd88pURl2lPs8hgHyL0r5vRCPlKW52L2mzrnN2t+jIlcFnu9fr3eGL7OhmCnykHr3/965tHPvKRIy9ws8h2ZLTEiflslquL1dbrcnLjJgsapi+URTFTtsGRn6vpJ61mtGU+g1F1nR0n+p/DUqyJwG6X+W6jUsl+PYKlhuTvTrnAH5yL9rnPfa5bPTZb/y0lq9qmEcof6eHy59/D2+hkPlrmt2UboN2dymaef1bbTbl72SliqTsgayENWMrw8pe/vHuv1akMBx54YNehyUV9Rd/wD9dZAppREhjks8zvWR8iZHRBwoF+h4n+8UHZDjKyEjEArEbuBGd9oCOPPHKXn2Wa3fDWi9nNaHC7wszLz0VtLrhH3aEflIvShObPfe5zF7WN2VY6Q9ezqn9ke+OE/mkvh1+/f14u5q95zWt2WwaOuomTvkVvsJ8Tududu+l9e55V/DMff1BCg0wX6I/JXflMWcid9FH9o/71sptE6iIXz4PD8TMtdHgu/ijZMSOjAHIRnBBhWNaNyE4aKc/gzgzVz2alulhNva4kn3cCi9y4yVdulgxOfVhNP6m/sTVqK9BRfc30MzNFtJc1p7LrQ8KUEzOCg63DSAR2u2z7k4YmQ8pzVzrJeYZg5Q9j/igl0V1r+UOflDoLI+UPfv7QZpj9EUccseRz0hAeddRR3TD+zInLnfc0jEn909hkoZk0WHH729++u1DOEL78Ac7iTPmDnz++eTzb6+S5yy0wuJyUM0MBM0wt2xf1WzwmFe6H5w1KA5w7AKPc8Y53PNEdprzffKVxqybtmUOYTlb2PT7kkENWPD6djaT7WYAzHY7MH8zQwaVGMyQgyFacO3fuXBQW5BxpzPM7Nmp7qHRMMnrB9o4ArFa24MsWj2n3s7ZT2rfchc7d4Ez9y1bSWfeplxGNWQw6WzJm/YAE8hkpl+0EV5KpEemL5KZG+gFZqDoXyxnunumhfbueKRfZOjHTC3IBnP5VLs5zJzlrBWW6Qb8ORPpE+++/f3fzI3fRU5ZcPGb6Zdauilw05sI4i0Wm3c+WhlnkLyMS+7v1mbef/kGOzdSE9I9yrn7757TpKVPWD0jIkcfzfrIFZC7sM5Ij22JG6jKBSMp22GGHdfP+s612tjYcXndqlGyrmMUQcwMh7yXbRWaUSBZdTp8oNxcSUgyrfDYr1cVq6nUl+T3Kjaysd5B+ZLYVPbH9pH476wQrqfucO78fo0bNpv7SX80NtmzxmPeZ+sp5s0Xl8JQeWGSjt4dg88lWe9lGcN999+22BMw2RRe+8IXb+973vu0vf/nL0haPn//850duD5htmQbluac73el22eIxW9w885nPbPfee+/2VKc6VXu1q12t/epXvzrynMOy7U+24cl585X3cfjhh3dbHw776Ec/2t761rfutgY6xSlO0Z7hDGdoL3/5y3fnzhY9w+91qe2Chushvva1r3XbN5761Kduz3ve87ZHHnlk+7KXvWxVWzwOvr+l6rCv81HbAV3lKlfpfjY1NdWuxqUudan2bne726LHlnr9yNZa2Woy20JlC6iJiYn2Zz/7WXd8njfoT3/6U7el41577bVoS6TXvva13fF3utOddjl/tinKZ/SoRz1qVe8DgM1hqf7FsOF+xbCXvvSl7eUud7luW8i0Q9niL1tZp80abu+zvXXaw/RD0peYn59fVZmypWOel/7FOc95zm6L4uGtHOOTn/xke93rXrcrT8qe1xzepvn73/9+e+c737k917nO1Z0v/Yob3/jG7Zvf/OaFY4466qhuG+W0xXl/ee1sb91v0f2b3/ym6w/l8bxO2usrXelK7dzc3C5lyraA2a47x6Qfc6ELXag99NBD2y984Qu79LmydWDqaL/99mvf+ta3dp/BSls8Drbvqcf0V9IHy2td4hKXaB//+Me3f/7zn3c5vvrZrFQXq6nXyu/eBz7wge6YbGee7UdPSj8p/cWUI9tEDvbvRvU1U/70Y3Pe1F3e8zHHHLPomH6Lx+E66vvceX9sPdvyP4tjBRhfGUGQEQHZGaEfNcD6yyiKww8/vLvzMLzt1EbI9JaMHskiSblLAwBrJSPisqr9Mccco5KBTck4FWC3u8Md7tBNHchQvz1BhjpmCKIAAQAAThprIgC7XebRDW+BuZEGFw0CAABOPCMRAAAAgBJrIgAAAAAlRiIAAAAAJUIEAAAAoESIAAAAAOze3Rmmp6erhwLApjEzM7PRRWADzM/Pq3cAtpyJiYkVjzESAQAAACgRIgAAAAAlQgQAAACgRIgAAAAAlAgRAAAAgBIhAgAAAFAiRAAAAABKhAgAAABAiRABAAAAKBEiAAAAACVCBAAAAKBEiAAAAACUCBEAAACAEiECAAAAUCJEAAAAAEqECAAAAECJEAEAAAAoESIAAAAAJUIEAAAAoESIAAAAAJQIEQAAAIASIQIAAABQIkQAAAAASoQIAAAAQIkQAQAAACgRIgAAAAAlQgQAAACgRIgAAAAAlAgRAAAAgBIhAgAAAFAiRAAAAABKhAgAAABAiRABAAAAKBEiAAAAACVCBAAAAKBEiAAAAACUCBEAAACAEiECAAAAUCJEAAAAAEqECAAAAECJEAEAAAAoESIAAAAAJUIEAAAAoESIAAAAAJQIEQAAAICS7c0mNzs724yTqampsSpzyhvKvPb1PE51HMq8PnUc41hmYG1MTk6OVdXOzc2NVZlT3lDmta/ncarjUOb1qeMYxzJvNkYiAAAAACVCBAAAAKBEiAAAAACUCBEAAACAEiECAAAAUCJEAAAAAEqECAAAAECJEAEAAAAoESIAAAAAJUIEAAAAoESIAAAAAJQIEQAAAIASIQIAAABQIkQAAAAASoQIAAAAQIkQAQAAACgRIgAAAAAlQgQAAACgRIgAAAAAlAgRAAAAgBIhAgAAAFAiRAAAAABKhAgAAABAiRABAAAAKBEiAAAAACVCBAAAAKBEiAAAAACUCBEAAACAEiECAAAAUCJEAAAAAEqECAAAAECJEAEAAAAoESIAAAAAJUIEAAAAoESIAAAAAJQIEQAAAIASIQIAAABQIkQAAAAASoQIAAAAgBABAAAA2H2MRAAAAABKhAgAAABAiRABAAAAKNnWtm1bOXB6erp2RgDYRGZmZja6CGyA+fl59Q7AljMxMbHiMdubTW52drYZJ1NTU2NV5pQ3lHnt63mc6jiUeX3qOMaxzMDamJycHKuqnZubG6syp7yhzGtfz+NUx6HM61PHMY5l3mxMZwAAAABKhAgAAABAiRABAAAAKBEiAAAAACVCBAAAAKBEiAAAAACUCBEAAACAEiECAAAAUCJEAAAAAEqECAAAAECJEAEAAAAoESIAAAAAJUIEAAAAoESIAAAAAJQIEQAAAIASIQIAAABQIkQAAAAASoQIAAAAQIkQAQAAACgRIgAAAAAlQgQAAACgRIgAAAAAlAgRAAAAgBIhAgAAAFAiRAAAAABKhAgAAABAiRABAAAAKBEiAAAAACVCBAAAAKBEiAAAAACUCBEAAACAEiECAAAAUCJEAAAAAEqECAAAAECJEAEAAAAoESIAAAAAJUIEAAAAoESIAAAAAJQIEQAAAIASIQIAAABQIkQAAAAASoQIAAAAQMm2tm3byoHT09O1MwLAJjIzM7PRRWADzM/Pq3cAtpyJiYkVjzESAQAAACjZ3mxys7OzzTiZmpoaqzKnvKHMa1/P41THoczrU8cxjmUG1sbk5ORYVe3c3NxYlTnlDWVe+3oepzoOZV6fOo5xLPNmYyQCAAAAUCJEAAAAAEqECAAAAECJEAEAAAAoESIAAAAAJUIEAAAAoESIAAAAAJQIEQAAAIASIQIAAABQIkQAAAAASoQIAAAAQIkQAQAAACgRIgAAAAAlQgQAAACgRIgAAAAAlAgRAAAAgBIhAgAAAFAiRAAAAABKhAgAAABAiRABAAAAKBEiAAAAACVCBAAAAKBEiAAAAACUCBEAAACAEiECAAAAUCJEAAAAAEqECAAAAECJEAEAAAAoESIAAAAAJUIEAAAAoESIAAAAAJQIEQAAAIASIQIAAABQIkQAAAAASoQIAAAAQIkQAQAAACgRIgAAAAAlQgQAAACgRIgAAAAAlAgRAAAAgBIhAgAAAFAiRAAAAABKtrVt21YOnJ6erp0RADaRmZmZjS4CG2B+fl69A7DlTExMrHiMkQgAAABAyfZmk5udnW3GydTU1FiVOeUNZV77eh6nOg5lXp86jnEsM7A2Jicnx6pq5+bmxqrMKW8o89rX8zjVcSjz+tRxjGOZNxsjEQAAAIASIQIAAABQIkQAAAAASjb9mgjL6WeorLz+5EmXNZ7HZ/YOALDZ3OY2t+m+77fffmv+Wscdd1zzpje9ac1fB4D1t6VDhKPXMUToXwsAYCN8+tOfXrcQoX8tADYf0xkAAACAki09EuEz//t+bNM0B67Raxw79FoAABth586dC9/33nvvNX8NADanLR0iDK5XcOAanhsAYE+R9QrWKkTIuQHY3ExnaJrmWWt87rU8PwDAnrJeQc5tPQSAzU2IAAAAAJQIEdZw9wQ7MgAAe6K1GC1gBALA1iBEWMO1C6yHAADsidZi7QLrIQBsDUIEAAAAoESIMLAF47EDWzKeVDmPbR0BgD1RtmDsv3bn+QDY/IQIa7STgh0ZAIA92e7cScF6CABbx/aNLsCepF/DIDn6id09uc/grYcAAOzJ+jUMTjjhhGavvfY6UefIcwfPBcDmZyQCAAAAUCJEGGH+JD7XKAQAYFzs2LHjJD33pDwfgPEjRNjN6xnsznUVAADW2klZz2B3rqsAwHgQIgAAAAAlFlYc4fiBKQkTTd38/54LADAusjhivzDifvvtV35entMvrAjA1iFEWMLRJyJE6J8DADBO+ikJqwkRTGMA2JqECEv4zCq2e9w59BwAgHGyc+fO8naP/eiD/jkAbC3WRAAAAABKhAgrqOy0YEcGAGAzqExRsCMDwNYmRFjBfPGYynEAAHuyHTt2lI6pHAfA5iREAAAAAEqECCs4foVdF47+3zG2dgQAxl0WTVxuSkN+lmNs7QiwdQkRCpabqmAaAwCwmRx33HEn6mcAbA1ChIJs3Xjs/74G5d+2dQQANpNs3dh/jXocgK1NiAAAAACUbK8dRj9t4cCBqjCVAQDYjPppC3vvvfcujwGwtQkRip71v+8PHPEYAMBm0i+ueNBBB+3yGABbm+kMAAAAQImRCKtkCgMAsFXs2LFjo4sAwB5GiLBKpjAAAFuFKQwADBMirNLxq30CAMCYOuGEEza6CADsYayJAAAAAJQIEQAAAIASIQIAAABQIkQAAAAASoQIAAAAQMm2tm3byoHT09O1MwLAJjIzM7PRRWADzM/Pq3cAtpyJiYkVj9n0WzzOzs4242RqamqsypzyhjKvfT2PUx2HMq9PHcc4lhlYG5OTk2NVtXNzc2NV5pQ3lHnt63mc6jiUeX3qOMaxzJuN6QwAAABAiRABAAAAKBEiAAAAACVCBAAAAKBEiAAAAACUCBEAAACAEiECAAAAUCJEAAAAAEqECAAAAECJEAEAAAAoESIAAAAAJUIEAAAAoESIAAAAAJQIEQAAAIASIQIAAABQIkQAAAAASoQIAAAAQIkQAQAAACgRIgAAAAAlQgQAAACgRIgAAAAAlAgRAAAAgBIhAgAAAFAiRAAAAABKhAgAAABAiRABAAAAKBEiAAAAACVCBAAAAKBEiAAAAACUCBEAAACAEiECAAAAUCJEAAAAAEqECAAAAECJEAEAAAAoESIAAAAAJUIEAAAAoESIAAAAAJQIEQAAAIASIQIAAABQIkQAAAAASoQIAAAAQIkQAQAAACgRIgAAAAAl29q2bSsHTk9P184IAJvIzMzMRheBDTA/P6/eAdhyJiYmVjxme7PJzc7ONuNkampqrMqc8oYyr309j1MdhzKvTx3HOJYZWBuTk5NjVbVzc3NjVeaUN5R57et5nOo4lHl96jjGscybjekMAAAAQIkQAQAAACgRIgAAAAAlQgQAAACgRIgAAAAAlAgRAAAAgBIhAgAAAFAiRAAAAABKhAgAAABAiRABAAAAKBEiAAAAACVCBAAAAKBEiAAAAACUCBEAAACAEiECAAAAUCJEAAAAAEqECAAAAECJEAEAAAAoESIAAAAAJUIEAAAAoESIAAAAAJQIEQAAAIASIQIAAABQIkQAAAAASoQIAAAAQIkQAQAAACgRIgAAAAAlQgQAAACgRIgAAAAAlAgRAAAAgBIhAgAAAFAiRAAAAABKhAgAAABAiRABAAAAKBEiAAAAACVCBAAAAKBEiAAAAACUCBEAAACAEiECAAAAUCJEAAAAAEqECAAAAECJEAEAAAAoESIAAAAAJdvatm0rB05PT9fOCACbyMzMzEYXgQ0wPz+v3gHYciYmJlY8Znuzyc3OzjbjZGpqaqzKnPKGMq99PY9THYcyr08dxziWGVgbk5OTY1W1c3NzY1XmlDeUee3reZzqOJR5feo4xrHMm43pDAAAAECJEAEAAAAoESIAAAAAJUIEAAAAoESIAAAAAJQIEQAAAAAhAgAAALD7GIkAAAAAlAgRAAAAgBIhAgAAAFAiRAAAAABKhAgAAABAiRABAAAAKBEiAAAAACVCBAAAAKBEiAAAAACUCBEAAACAEiECAAAAUCJEAAAAAEqECAAAAECJEAEAAAAoESIAAAAAJUIEAAAAoESIAAAAAJQIEQAAAIASIQIAAABQIkQAAAAASoQIAAAAQIkQAQAAACgRIgAAAAAlQgQAAACgRIgAAAAAlAgRAAAAgBIhAgAAAFAiRAAAAABKhAgAAABAiRABAAAAKBEiAAAAACVCBAAAAKBEiAAAAACUCBEAAACAEiECAAAAULKtbdu2cuD09HQzbmZnZptxMzU9tdFFAGDAzMyM+tiC5ufnm3EzMTHRjJtxrGeAzazSlhiJAAAAAJRsrx3GepqdHZ8RFFNT/3/khDKvfT2PUx2HMq9PHcc4lhmgNzk5OTaVMTc3131X5rWv53Gq41Dm9anjGMcybzZGIgAAAAAlQgQAAACgRIgAAAAAlAgRAAAAgBIhAgAAAFAiRAAAAABKhAgAAABAiRABAAAAKBEiAAAAACVCBAAAAKBEiAAAAACUCBEAAACAEiECAAAAUCJEAAAAAEqECAAAAECJEAEAAAAoESIAAAAAJUIEAAAAoESIAAAAAJQIEQAAAIASIQIAAABQIkQAAAAASoQIAAAAQIkQAQAAACgRIgAAAAAlQgQAAACgRIgAAAAAlAgRAAAAgBIhAgAAAFAiRAAAAABKhAgAAABAiRABAAAAKBEiAAAAACVCBAAAAKBEiAAAAACUCBEAAACAEiECAAAAUCJEAAAAAEqECAAAAECJEAEAAAAoESIAAAAAJUIEAAAAoGRb27Zt5cDp6enaGQFgE5mZmdnoIrAB5ufn1TsAW87ExMSKxxiJAAAAAJQIEQAAAIASIQIAAABQIkQAAAAASoQIAAAAQIkQAQAAACgRIgAAAAAlQgQAAACgRIgAAAAAlAgRAAAAgBIhAgAAAFAiRAAAAABKhAgAAABAiRABAAAAKBEiAAAAACVCBAAAAKBEiAAAAACUCBEAAACAEiECAAAAUCJEAAAAAEqECAAAAECJEAEAAAAoESIAAAAAJUIEAAAAoESIAAAAAJQIEQAAAIASIQIAAABQIkQAAAAASoQIAAAAQIkQAQAAACgRIgAAAAAlQgQAAACgRIgAAAAAlAgRAAAAgBIhAgAAAFAiRAAAAACECAAAAMDuYyQCAAAAUCJEAAAAAEqECAAAAECJEAEAAAAoESIAAAAAJUIEAAAAoESIAAAAAJRsa9u2rR0KAAAAbGVGIgAAAAAlQgQAAACgRIgAAAAAlAgRAAAAgBIhAgAAAFAiRAAAAABKhAgAAABAiRABAAAAKBEiAAAAAE3F/wNkKfGckPoVUgAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize environment with preprocessing\n",
        "env = SimpleGridEnv(max_steps=100, preprocess=pre_process)\n",
        "obs = env.reset()[0]\n",
        "\n",
        "print(\"=== SimpleGridEnv ===\")\n",
        "print(f\"Action space:       {env.action_space}\")\n",
        "print(f\"Number of actions:  {env.action_space.n}\")\n",
        "print(f\"Observation space:  {env.observation_space}  (ensure it matches preprocessing output)\")\n",
        "print(f\"Observation shape:  {obs.shape}\")\n",
        "print(f\"Agent direction:    {env.agent_dir}\")\n",
        "print(f\"Agent position:     {env.agent_pos}\")\n",
        "print(f\"Goal position:      {env.goal_pos}\")\n",
        "\n",
        "# Side-by-side view of raw and preprocessed observations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].imshow(env.render())\n",
        "axes[0].set_title(\"SimpleGridEnv (raw)\")\n",
        "axes[0].axis(\"off\")\n",
        "axes[1].imshow(obs.squeeze(), cmap=\"gray\")\n",
        "axes[1].set_title(\"Preprocessed Observation\")\n",
        "axes[1].axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3Qs2iJl6BCg"
      },
      "source": [
        "## Environment 2: KeyDoorBallEnv (Key-Door-Ball Task)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNNOKucFjPRK"
      },
      "source": [
        "**Task**: Complete a multi-step objective: Key â†’ Door â†’ Ball â†’ Goal\n",
        "\n",
        "| Property | Value |\n",
        "|----------|-------|\n",
        "| Grid Size | 8Ã—8 (two rooms) |\n",
        "| Partition Wall | Column 3 |\n",
        "| Key Location | Left room (random) |\n",
        "| Door Location | In partition wall (random row) |\n",
        "| Ball Location | Right room (random) |\n",
        "| Goal Position | Fixed at (8, 8) |\n",
        "| Actions | 0: Left, 1: Right, 2: Forward, 3: Pickup, 4: Toggle |\n",
        "\n",
        "**Sequence**: Pick up key â†’ Open door â†’ Enter right room â†’ Pick up ball â†’ Reach goal\n",
        "\n",
        "**Helper Methods** (use in reward shaping):\n",
        "- `is_carrying_key()` â€” True if agent has the key\n",
        "- `is_carrying_ball()` â€” True if agent has the ball\n",
        "- `is_door_open()` â€” True if door is open"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0XAsSMBjPRK"
      },
      "source": [
        "### Quick Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "bsZpzNRe6Gen",
        "outputId": "ef92861a-5bae-42c3-a4a4-d901e46a0290"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== KeyDoorBallEnv ===\n",
            "Action space:       Discrete(5)\n",
            "Number of actions:  5\n",
            "Observation space:  Box(0, 255, (320, 320, 1), uint8)  (ensure it matches preprocessing output)\n",
            "Observation shape:  (320, 320, 1)\n",
            "Agent direction:    0\n",
            "Agent position:     (1, 1)\n",
            "Goal position:      (8, 8)\n",
            "Carrying key:       False\n",
            "Door open:          False\n",
            "Carrying ball:      False\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Initialize environment\n",
        "env = KeyDoorBallEnv(max_steps=5000, preprocess=pre_process)\n",
        "obs = env.reset()[0]\n",
        "\n",
        "print(\"=== KeyDoorBallEnv ===\")\n",
        "print(f\"Action space:       {env.action_space}\")\n",
        "print(f\"Number of actions:  {env.action_space.n}\")\n",
        "print(f\"Observation space:  {env.observation_space}  (ensure it matches preprocessing output)\")\n",
        "print(f\"Observation shape:  {obs.shape}\")\n",
        "print(f\"Agent direction:    {env.agent_dir}\")\n",
        "print(f\"Agent position:     {env.agent_pos}\")\n",
        "print(f\"Goal position:      {env.goal_pos}\")\n",
        "print(f\"Carrying key:       {env.is_carrying_key()}\")\n",
        "print(f\"Door open:          {env.is_door_open()}\")\n",
        "print(f\"Carrying ball:      {env.is_carrying_ball()}\")\n",
        "\n",
        "# Side-by-side view of raw and preprocessed observations\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "axes[0].imshow(env.render())\n",
        "axes[0].set_title(\"KeyDoorBallEnv (raw)\")\n",
        "axes[0].axis(\"off\")\n",
        "axes[1].imshow(obs.squeeze(), cmap=\"gray\")\n",
        "axes[1].set_title(\"Preprocessed Observation\")\n",
        "axes[1].axis(\"off\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "7RjyZDC_jPRK",
        "outputId": "9ad92551-2fbc-4519-8406-8a3e667a0cb9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "=== Episode Summary ===\n",
            "Steps:         100\n",
            "Total reward:  0.000\n",
            "Terminated:    False\n",
            "Truncated:     True\n",
            "\n",
            "=== Environment Status (End of Episode) ===\n",
            "Agent position:  (np.int64(2), np.int64(5))\n",
            "Carrying key:    True\n",
            "Door open:       False\n",
            "Carrying ball:   False\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<img src=\"data:image/gif;base64,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\" width=\"640\">"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Random action rollout + video\n",
        "max_steps = 100\n",
        "env = KeyDoorBallEnv(max_steps=max_steps, preprocess=pre_process)\n",
        "num_actions = env.action_space.n\n",
        "obs = env.reset()[0]\n",
        "\n",
        "# TODO: Restore to \"/content/KeyDoorBallEnv_random.mp4\" when moving to Colab\n",
        "# video_filename = \"/content/KeyDoorBallEnv_random.mp4\"\n",
        "video_filename = \"outputs/KeyDoorBallEnv_random.gif\"  # macOS/local: GIF works without ffmpeg\n",
        "\n",
        "with imageio.get_writer(video_filename, fps=10) as video:\n",
        "    obs, _ = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0\n",
        "    for step in range(max_steps):\n",
        "        action = random.randint(0, num_actions - 1)\n",
        "        obs, reward, terminated, truncated, _ = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        total_reward += reward\n",
        "        video.append_data(env.render())\n",
        "        if done:\n",
        "            break\n",
        "\n",
        "# Print episode summary\n",
        "print(\"=== Episode Summary ===\")\n",
        "print(f\"Steps:         {step + 1}\")\n",
        "print(f\"Total reward:  {total_reward:.3f}\")\n",
        "print(f\"Terminated:    {terminated}\")\n",
        "print(f\"Truncated:     {truncated}\")\n",
        "print()\n",
        "print(\"=== Environment Status (End of Episode) ===\")\n",
        "print(f\"Agent position:  {env.agent_pos}\")\n",
        "print(f\"Carrying key:    {env.is_carrying_key()}\")\n",
        "print(f\"Door open:       {env.is_door_open()}\")\n",
        "print(f\"Carrying ball:   {env.is_carrying_ball()}\")\n",
        "\n",
        "# TODO: Restore to embed_mp4(video_filename) when moving to Colab\n",
        "embed_video(video_filename)  # Works for both mp4 and gif"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPJZuciHjPRK"
      },
      "source": [
        "# Part 1: Reward Shaping\n",
        "\n",
        "## 1.1 SimpleGridEnv Reward Shaping\n",
        "Design reward shaping for the simple navigation task:\n",
        "- Distance-based rewards (closer to goal = higher reward)\n",
        "- Step penalty to encourage efficiency\n",
        "- Consider potential-based shaping to avoid reward hacking"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vO4qOpN1jPRK"
      },
      "outputs": [],
      "source": [
        "# SimpleGridEnv reward shaping implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.2 KeyDoorBallEnv Reward Shaping\n",
        "Design reward shaping for the multi-step task:\n",
        "- Milestone rewards: key pickup, door open, ball pickup\n",
        "- Use `is_carrying_key()`, `is_door_open()`, `is_carrying_ball()` helpers\n",
        "- Use `prev_key`, `prev_door`, `prev_ball` to detect state changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# KeyDoorBallEnv reward shaping implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 2: Deep Learning Components\n",
        "\n",
        "## 2.1 CNN Feature Extractor\n",
        "Implement a CNN backbone for processing image observations:\n",
        "- Convolutional layers to extract spatial features\n",
        "- Will be shared/reused by different network architectures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CNN Feature Extractor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 Q-Network (for DQN)\n",
        "Neural network that outputs Q-values for each action:\n",
        "- Input: preprocessed image\n",
        "- Output: Q-value for each action"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Q-Network for DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.3 Policy Network (for REINFORCE)\n",
        "Neural network that outputs action probabilities:\n",
        "- Input: preprocessed image\n",
        "- Output: probability distribution over actions (softmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Policy Network for REINFORCE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 3: Reinforcement Learning Components\n",
        "\n",
        "## 3.1 Replay Buffer\n",
        "Experience replay buffer for DQN:\n",
        "- Store transitions (state, action, reward, next_state, done)\n",
        "- Sample random batches for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Replay Buffer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2 Exploration Strategy\n",
        "Epsilon-greedy exploration with decay:\n",
        "- Start with high exploration (epsilon â‰ˆ 1.0)\n",
        "- Gradually decrease to low exploration (epsilon â‰ˆ 0.01)\n",
        "- Balance exploration vs exploitation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Epsilon-Greedy Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.3 Target Network Utilities\n",
        "Utilities for managing the target network in DQN:\n",
        "- Hard update: copy weights periodically\n",
        "- Soft update: gradual weight blending (optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Target Network Update Utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 4: Training Utilities\n",
        "\n",
        "## 4.1 Metrics Logger\n",
        "Track and visualize training progress:\n",
        "- Episode rewards and lengths\n",
        "- Loss curves\n",
        "- Moving averages for smoothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Metrics Logger"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.2 Video Recording\n",
        "Record agent behavior during and after training:\n",
        "- Capture frames during rollouts\n",
        "- Save as GIF/MP4 for visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Video Recording Utility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.3 Evaluation Function\n",
        "Evaluate trained agent performance:\n",
        "- Run 100 episodes without exploration\n",
        "- Compute average steps and rewards\n",
        "- Required metric for the assignment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation Function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 5: DQN Algorithm\n",
        "\n",
        "## 5.1 DQN Agent\n",
        "Implement the DQN agent class:\n",
        "- Q-network and target network\n",
        "- Action selection (epsilon-greedy)\n",
        "- Learning step (batch update)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DQN Agent Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.2 DQN Training Loop\n",
        "Training loop for DQN:\n",
        "- Collect experiences\n",
        "- Store in replay buffer\n",
        "- Sample batches and update Q-network\n",
        "- Periodically update target network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DQN Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 6: Policy Gradient (REINFORCE)\n",
        "\n",
        "## 6.1 REINFORCE Agent\n",
        "Implement the REINFORCE agent class:\n",
        "- Policy network\n",
        "- Action sampling from distribution\n",
        "- Compute returns and policy gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# REINFORCE Agent Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.2 REINFORCE Training Loop\n",
        "Training loop for REINFORCE:\n",
        "- Collect full episode trajectories\n",
        "- Compute discounted returns\n",
        "- Update policy using policy gradient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# REINFORCE Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 7: Experiments â€” SimpleGridEnv\n",
        "\n",
        "## 7.1 DQN on SimpleGridEnv\n",
        "Train and evaluate DQN on the simple navigation task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DQN on SimpleGridEnv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7.2 REINFORCE on SimpleGridEnv\n",
        "Train and evaluate REINFORCE on the simple navigation task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# REINFORCE on SimpleGridEnv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7.3 SimpleGridEnv Results & Comparison\n",
        "Compare DQN vs REINFORCE on SimpleGridEnv:\n",
        "- Learning curves overlay\n",
        "- Final performance metrics\n",
        "- Analysis of strengths/weaknesses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "# SimpleGridEnv comparison plots and analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 8: Experiments â€” KeyDoorBallEnv\n",
        "\n",
        "## 8.1 DQN on KeyDoorBallEnv\n",
        "Train and evaluate DQN on the multi-step task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DQN on KeyDoorBallEnv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8.2 REINFORCE on KeyDoorBallEnv\n",
        "Train and evaluate REINFORCE on the multi-step task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# REINFORCE on KeyDoorBallEnv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8.3 KeyDoorBallEnv Results & Comparison\n",
        "Compare DQN vs REINFORCE on KeyDoorBallEnv:\n",
        "- Learning curves overlay\n",
        "- Final performance metrics\n",
        "- Analysis of strengths/weaknesses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "# KeyDoorBallEnv comparison plots and analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 9: Hyperparameter Studies\n",
        "\n",
        "## 9.1 Learning Rate Study\n",
        "Experiment with different learning rates and analyze impact on training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Learning Rate Study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9.2 Exploration (Epsilon) Study\n",
        "Experiment with different epsilon decay schedules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Epsilon Study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9.3 Replay Buffer Size Study\n",
        "Experiment with different buffer sizes (DQN only)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9.4 Target Network Update Frequency\n",
        "Experiment with different update frequencies (DQN only)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Target Network Update Frequency Study"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Architecture / Initialization Study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part 10: Conclusions\n",
        "\n",
        "## 10.1 Summary Table\n",
        "Summary of all experiment results:\n",
        "| Environment | Algorithm | Avg Steps | Avg Reward | Notes |\n",
        "|-------------|-----------|-----------|------------|-------|\n",
        "| SimpleGridEnv | DQN | | | |\n",
        "| SimpleGridEnv | REINFORCE | | | |\n",
        "| KeyDoorBallEnv | DQN | | | |\n",
        "| KeyDoorBallEnv | REINFORCE | | | |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10.2 Key Findings\n",
        "Document key insights from experiments:\n",
        "- Which algorithm performed better and why?\n",
        "- What hyperparameters had the most impact?\n",
        "- What reward shaping strategies worked best?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10.3 Strengths & Weaknesses\n",
        "Analysis of DQN vs REINFORCE:\n",
        "\n",
        "**DQN Strengths:**\n",
        "- \n",
        "\n",
        "**DQN Weaknesses:**\n",
        "- \n",
        "\n",
        "**REINFORCE Strengths:**\n",
        "- \n",
        "\n",
        "**REINFORCE Weaknesses:**\n",
        "-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10.4 Limitations & Future Work\n",
        "Document limitations and potential improvements:\n",
        "- What didn't work as expected?\n",
        "- What would you try with more time/resources?"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "RXbtXcLijPRI",
        "8MHBOpXqjPRJ"
      ],
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
